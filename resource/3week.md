# 딥러닝이란?

알파고의 대두 이후로, 딥러닝에 대한 관심에 많아지고 있습니다. 
이러한 딥러닝의 결과로 

> "딥러닝 썼더니 바둑도 잘 두던데? 우리 비즈니스에도 딥러닝 적용하면 전부 대체 가능하겠네!!"

라는 '딥러닝 만능주의'가 생겨나고 있다는 느낌을 지울 수 없습니다. 그러나, 현재의 딥러닝에는 엄연한 약점이 존재하며, 아직까지는 특정 부류 업무의 자동화를 위한 하나의 도구로 보아야 합당합니다.

이번에는 딥러닝이란 기술이 본질적으로 무엇인지, 어떤 강점과 약점이 있는지, 어떠한 문제에 효과적으로 적용될 수 있는지 등을 중심으로 이야기해 보고자 합니다. 

# 딥러닝 ⊂ 머신러닝 
_딥러닝은 머신러닝의 세부 방법론들을 통칭하는 개념에 불과_ 합니다.즉, 이론적으로 딥러닝은 머신러닝의 '부분집합'이라고 할 수 있으며, 사실 기존 머신러닝 이론에서 크게 새로울 것은 없습니다. 

이 부분에 대해서는 보다 수학적인 설명이 필요한데, 이에 앞서 살펴본 **머신러닝의 핵심 요소**를 다시 한번 보도록하자.

## 머신러닝의 핵심 요소

1. 데이터 
2. 러닝 모델 (+ 러닝 알고리즘)
3. 요인 추출

엄밀히 말하면, 요인 추출(feature extraction)은 _필수적인_ 것은 아니나, 머신러닝의 성패를 크게 좌우하는 것이라 **핵심 요소** 리스트에 추가를 했습니다.
머신러닝을 위해서는 데이터와 러닝 모델이 필요하며, 성공적인 학습 위해서는 우선 데이터를 면밀히 조사하고 그 특징을 파악한 뒤, 이에 가장 적합한 러닝 모델을 잘 골라야 하며, 원데이터를 그대로 사용하는 것보다는 효과적인 요인을 새로 정의하여, 이를 추출한 뒤 러닝 모델에 입력해주는 것이 좋다. 

## 퍼셉트론 - 선형 모델의 일반화 

이전에 러닝 모델의 예시로 든, 선형 모델을 참고하자면,

![그림1](http://research.sualab.com/assets/images/what-is-machine-learning/age-to-salary-classify-sample-plot.png)

선형 모델을 매번 위와 같은 수식으로 표현하면 한 번에 알아보기 불편하므로, 아래와 같이 좀 더 예쁜 그림으로 표현할 수 있습니다.

![그림2](http://research.sualab.com/assets/images/what-is-deep-learning-1/linear-model-diagram.svg)

위 그림을 보시면, 기뵨 뼈대에 w0, w1, w2가 있고, 여기에 1, x1, x2가 각각 곱해진 후, 이들을 모두 합산한(∑) 결과를 그대로 출력하고 있습니다. 일반적으로는 합산 결과에 **활성함수(activation function)** 라는 모종의 함수 σ(⋅)를 적용한 결과를 최종 출력값으로 대신 출력하는 경우가 많습니다.
여기에, d개의 입력 변수값으로 구성된 _d차원_ 데이터 예시 (x1, x2, ..., xd)를 받아드리는 상황을 가정하면 아래와 같은 일반화된 그림을 표현할 수 있습니다.

![그림3](http://research.sualab.com/assets/images/what-is-deep-learning-1/perceptron-diagram.svg)

일관성을 위해, 기존에 w0이 등장하는 항에 x0 = 1이 곱해진다고 가정하면, 입력 벡터 x = (x1, x2, ..., xd)를 받아드린 뒤 각 성분에 가중치를 곱하고, 그 결과를 모두 합산 한 후, 활성함수 σ(⋅)를 적용할 수 있다고 할 수 있습니다.
전체 과정을 수행하는 이 선형 모델을 하나의 함수 h(⋅)로 나타낼 수 있으며, 이를 **퍼셉트론** 이라고 부릅니다.

이 때, x0 = 1까지 포함된 (d+1)차원벡터를 받아드리므로, 이를 편의상 (d+1)차원 퍼셉트론으로 부릅니다. 당연히, 활성함수로 항등함수 σ(s) = s를 사용할 수 있는 경우 이것은 위에서 살펴본 선형 모델이 됩니다.

> 선형 모델은, 따라서 퍼셉트론의 특수한 형태로 해석할 수 있습니다.

퍼셉트론의 모양을 가만히, 살펴보면 신경계의 기본 단위는 [뉴런(Neuron)](https://ko.wikipedia.org/wiki/%EC%8B%A0%EA%B2%BD_%EC%84%B8%ED%8F%AC)과 모양이 매우 흡사합니다. 이러한 유사성 때문에, 퍼셉트론을 흔히 인공 뉴런(Artificial Neuron) 혹은 줄여서 뉴런이라고 부릅니다.

![그림4](http://research.sualab.com/assets/images/what-is-deep-learning-1/neuron.png)

## 인공신경망 - 퍼셉트론의 조합 및 확장의 결과 

신경계에서의 뉴런들의 수는 엄청나게 많으며, 서로간 매우 복잡한 구조로 얽히고설켜 하나의 거대한 망을 구성합니다. 이를 신경망(Neural Network)이라 합니다. 
머신러닝 과학자들은 이러한 신경망 구조에 착안하여, 퍼셉트론을 하나의 빌딩 블록이라고 생각하고, 여러 개의 퍼셉트론을 아래 에시와 같이 연결한 [인공신경망(Artificial Neural Network)](https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B3%B5_%EC%8B%A0%EA%B2%BD%EB%A7%9D)을 고안하였습니다.

![그림5](http://research.sualab.com/assets/images/what-is-deep-learning-1/neural-network-detailed.svg)

위 그림에서 입력 벡터 x=(x1,x2,...,xd)가 각각 상단, 중단, 하단에 위치한, 서로 다른 (d+1)차원 퍼셉트론의 입력값으로 들어갑니다(이를 각각 초록색, 붉은색, 보라색으로 표현했습니다). 각각의 퍼셉트론에서 가중합 및 합성함수를 거친 3개의 출력값이 x0=1과 함께 4차원 퍼셉트론으로 입력됩니다. 4차원 퍼셉트론에서도 최종적으로 가중합 및 합성함수를 거치고, 최종적으로 1개의 값을 출력합니다.

위와 같이 연결한 구조에서, 세 개의 층(layer)을 확인하실 수 있나요? 입력 벡터가 위치한 층을 첫 번째 층, 3개의 (d+1)

차원 퍼셉트론이 나란히 붙어 출력한 값들이 위치하는 두 번째 층, 1개의 4차원 퍼셉트론이 출력한 값이 위치하는 세 번째 층으로 보시면 됩니다. 층 사이의 퍼셉트론들은 낮은(앞쪽) 층의 벡터를 각각 입력으로 받아 출력값을 내뱉고, 이는 높은(뒷쪽) 층의 벡터로 위치하는 구조를 확인할 수 있습니다.

더 거대한 인공신경망 구조를 표현하기 위해, 지금부터는 하나의 퍼셉트론을 아래와 같이 좀 더 단순화시켜 표현해 보겠습니다. 그리고, 그림 상에서 입력값 또는 출력값을 나타내는 원형 부분을 노드(node)라고 표현할 것입니다.

![그림6](http://research.sualab.com/assets/images/what-is-deep-learning-1/perceptron-simplified-diagram.svg)

그러면 총 3개의 층으로 구성되어 있으며, 첫 번째 층과 두 번째 층 사이에는 (d+1)차원 퍼셉트론이 H개, 두 번째 층과 세 번째 층 사이에는 (H+1)차원 퍼셉트론이 K개 있는 인공신경망을 아래와 같이 표현할 수 있습니다. 이 때, +1로 표시된 부분은 퍼셉트론이 위치하지 않으므로 주의하시길 바랍니다!

![그림7](http://research.sualab.com/assets/images/what-is-deep-learning-1/multilayer-perceptron.svg)

입력 벡터가 자리잡는 층을 입력층(input layer), 최종 출력값이 자리잡는 층을 출력층(output layer), 입력층과 출력층 사이에 위치하는 모든 층을 은닉층(hidden layer)이라고 합니다. 그림으로 표현할 때는 3개의 층을 그리나, 실제 인공신경망의 층 개수를 셀 때 입력층은 생략하는 것을 주의해야 합니다. 따라서 위 구조에서는 _‘총 2개의 층이 존재한다’_ 고 부릅니다. 퍼셉트론을 기본 빌딩 블록으로 하여, 이런 패턴에 따라 2차원적으로 연결되어 구성되는 인공신경망의 일종을 특별히 다층 퍼셉트론(MLP: multi-layer perceptron)이라고 합니다.

이런 입력층-은닉층-출력층의 경우, 다층 퍼셉트론뿐만 아니라, 좀 있다 설명할 다양한 인공신경망 구조에서 공통적으로 존재하는 층입니다. 은닉층의 개수가 많아질수록 인공신경망이 ‘깊어졌다(deep)’고 부르며, 이렇게 충분히 깊어진 인공신경망을 러닝 모델로 사용하는 머신러닝 패러다임을 바로 딥러닝(Deep Learning)이라고 합니다. 그리고, 딥러닝을 위해 사용하는 충분히 깊은 인공신경망을 심층 신경망(DNN: Deep neural network)이라고 통칭합니다.

‘그럼 은닉층 및 출력층이 몇 개 이상이 있어야 심층 신경망이냐?’는 의문이 생길 수 있는데, 일반적으로는 은닉층+출력층이 2개 이상이 되면 심층 신경망이라고 합니다. 예를 들어, 아래와 같이 8개 은닉층+출력층으로 구성된 다층 퍼셉트론은 심층 신경망입니다.

![그림8](http://research.sualab.com/assets/images/what-is-deep-learning-1/deep-neural-network-example.svg)

이제 여러분들은, **딥러닝은 머신러닝의 세부 방법론들에 불과하다** 는 말의 의미를 이해하셨을 것이라고 생각합니다. 머신러닝의 큰 틀은 그대로 가져가되, 러닝 모델로 ‘충분히 깊은’ 인공신경망을 사용하고, 이에 맞는 러닝 알고리즘을 사용하여 러닝 모델을 학습한 경우 ‘딥러닝을 했다’고 표현해도 크게 무리가 없습니다.

--- 

다음 주차에는 대표적인 딥러닝 모델과 텐서플로우 튜토리얼을 진행하도록 하겠습니다.
